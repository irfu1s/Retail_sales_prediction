# -*- coding: utf-8 -*-
"""Copy of Retail_Sales_Prediction_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MvSceWmIolfMfxoPxVKOa5xV8WSf8f4V

#  Retail Sales Prediction using Machine Learning

## üìå Objective
To predict retail store sales using historical data, including store types, promotions, holidays, and other relevant features. This project aims to help businesses forecast future sales more accurately.

---

##  Models Trained
| Model              | R¬≤ Score | RMSE     | MAE     |
|-------------------|----------|----------|---------|
| Linear Regression | 0.0900   | 21824.98 | 14564.77 |
| Decision Tree     | 0.9640   | 7152.62  | 4954.30 |
| Random Forest     | 0.0866   | 21824.98 | 14564.77 |
| **XGBoost**       | **0.9035** | **7094.16** | **4019.50** |

 **Best Performing Model**: XGBoost

---

## üõ† Tools Used
- Python, Pandas, Numpy
- Scikit-learn, XGBoost
- Matplotlib, Seaborn
- Google Colab

---

##  Key Takeaways
- XGBoost gave the highest R¬≤ score of **0.9035**, making it the best model.
- Decision Tree performed slightly better in R¬≤ but XGBoost had lower RMSE/MAE.
- Sales prediction models can help retailers with planning, inventory, and profit optimization.

---

# **Retail Sales Prediction using Machine Learning**

This project predicts retail sales using various regression models.  
The goal is to help businesses forecast revenue using historical data.

 **Tools Used: Python, Pandas, Scikit-learn, XGBoost, Google Colab  
 Project Type: Supervised Regression | Industry Use-case: Retail Analytics**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error,mean_absolute_error, r2_score

train=pd.read_csv('train.csv')
stores=pd.read_csv('stores.csv')
features=pd.read_csv("features.csv")

print("train Data:")
print(train.head(),"/n")

print("features Data:")
print(features.head(),"/n")

print("stores Data:")
print(stores.head(),"/n")

print("Missing values in train Data:")
print(train.isnull().sum(),"/n")

print("Missing values in features Data:")
print(features.isnull().sum(),"/n")

print("Missing values in stores Data:")
print(stores.isnull().sum(),"/n")

merged_df=pd.merge(train,features,on=['Store','Date'],how='left')
merged_df=pd.merge(merged_df,stores,on='Store',how='left')

print("Mergeed Datasets:\n",merged_df.head())

print("Missing values in merged data:\n",merged_df.isnull().sum())

markdown_cols=['MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5']
merged_df[markdown_cols]=merged_df[markdown_cols].fillna(0)

merged_df['CPI']=merged_df['CPI'].fillna(merged_df['CPI'].mean())
merged_df['Unemployment']=merged_df['Unemployment'].fillna(merged_df['Unemployment'].mean())

print("Any missing values left in the data?",merged_df.isnull().sum())

print("cleaned dataset:",merged_df.head())

merged_df.describe()

import matplotlib.pyplot as plt
import pandas as pd

merged_df['Date'] = pd.to_datetime(merged_df['Date'])

plt.figure(figsize=(14,6))
plt.plot(merged_df.groupby('Date')['Weekly_Sales'].sum(), color='blue')
plt.title("Total Weekly Sales Over Time", fontsize=16)
plt.xlabel("Date")
plt.ylabel("Weekly Sales")
plt.grid(True)
plt.show()

holiday_sales = merged_df.groupby('IsHoliday_x')['Weekly_Sales'].mean().reset_index()

plt.figure(figsize=(6, 4))
sns.barplot(x='IsHoliday_x', y='Weekly_Sales', data=holiday_sales, palette='viridis')
plt.title('Average Weekly Sales: Holiday vs Non-Holiday')
plt.xlabel('Is Holiday')
plt.ylabel('Avg Weekly Sales')
plt.show()

top_stores = merged_df.groupby('Store')['Weekly_Sales'].sum().sort_values(ascending=False).head(10)

plt.figure(figsize=(10, 5))
top_stores.plot(kind='bar', color='coral')
plt.title('Top 10 Stores by Total Sales')
plt.xlabel('Store')
plt.ylabel('Total Sales')
plt.grid(True)
plt.tight_layout()
plt.show()

merged_df['Date'] = pd.to_datetime(merged_df['Date'])
top_3_stores = merged_df.groupby('Store')['Weekly_Sales'].sum().nlargest(3).index
top3_df = merged_df[merged_df['Store'].isin(top_3_stores)]
plt.figure(figsize=(14, 6))
for store in top_3_stores:
    store_data = top3_df[top3_df['Store'] == store]
    store_data = store_data.sort_values('Date')
    plt.plot(store_data['Date'], store_data['Weekly_Sales'], label=f'Store {store}')

plt.title('Weekly Sales Trend for Top 3 Stores')
plt.xlabel('Date')
plt.ylabel('Weekly Sales')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

rolling_window = 4


weekly_sales = merged_df.groupby(['Store', 'Date'])['Weekly_Sales'].sum().reset_index()

plt.figure(figsize=(14, 6))

for store_id in top_3_stores:
    store_data = weekly_sales[weekly_sales['Store'] == store_id]
    store_data = store_data.set_index('Date')
    store_data['Smoothed_Sales'] = store_data['Weekly_Sales'].rolling(window=rolling_window).mean()
    plt.plot(store_data.index, store_data['Smoothed_Sales'], label=f'Store {store_id}')

plt.title(f'Smoothed Weekly Sales Trend (Top 3 Stores) - {rolling_window}-Week Rolling Avg')
plt.xlabel('Date')
plt.ylabel('Smoothed Weekly Sales')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

merged_df['Date'] = pd.to_datetime(merged_df['Date'])

merged_df['Year'] = merged_df['Date'].dt.year
merged_df['Month'] = merged_df['Date'].dt.month
merged_df['Week'] = merged_df['Date'].dt.isocalendar().week
merged_df['Day'] = merged_df['Date'].dt.day
merged_df['DayOfWeek'] = merged_df['Date'].dt.dayofweek

merged_df['Store_ID'] = merged_df['Store']

merged_df['IsPromo'] = merged_df['IsHoliday_x'].fillna(0).astype(int)

merged_df.head()

# Convert 'Type' column to one-hot encoding
merged_df = pd.get_dummies(merged_df, columns=['Type'], prefix='Type', dummy_na=False)

features = ['Store_ID', 'Dept', 'Year', 'Month', 'Week', 'Day', 'DayOfWeek',
            'Temperature', 'Fuel_Price', 'IsPromo', 'Size', 'Type_A', 'Type_B', 'Type_C']
target = 'Weekly_Sales'

X = merged_df[features]
y = merged_df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.head()

"""## Model Building and Evaluation

To predict retail sales, we experimented with the following regression models:

1. Linear Regression  
2. Decision Tree Regressor  
3. Random Forest Regressor  
4. XGBoost Regressor  (Best Performance)

We evaluated each model based on:
- **R¬≤ Score** (how well the model fits the data)
- **Root Mean Squared Error (RMSE)**
- **Mean Absolute Error (MAE)**

"""

# Define example values for the variables
temperature = 60.0
fuel_price = 3.5
store_type = 'A'


input_data = pd.DataFrame([{
    'Store_ID': 1,
    'Dept': 1,
    'Year': 2012,
    'Month': 12,
    'Week': 50,
    'Day': 15,
    'DayOfWeek': 6,
    'Temperature': temperature,
    'Fuel_Price': fuel_price,
    'IsPromo': 0,
    'Size': 151315,
    'Type_A': 1 if store_type == 'A' else 0,
    'Type_B': 1 if store_type == 'B' else 0,
    'Type_C': 1 if store_type == 'C' else 0
}])

lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

y_pred = lr_model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("linear regression results:")
print(f"Linear Regression MSE: {mse:.2f}")
print(f"Linear Regression R¬≤ Score: {r2:.2f}")

dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train, y_train)

dt_pred = dt_model.predict(X_test)

dt_mse = mean_squared_error(y_test, dt_pred)
dt_r2 = r2_score(y_test, dt_pred)

print("Decision Tree Regression Results:")
print(f"MSE: {dt_mse:.2f}")
print(f"R¬≤ Score: {dt_r2:.2f}")

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

rf_pred = rf_model.predict(X_test)

rf_mse = mean_squared_error(y_test, rf_pred)
rf_r2 = r2_score(y_test, rf_pred)

print("Random Forest Regression Results:")
print(f"MSE: {rf_mse:.2f}")
print(f"R¬≤ Score: {rf_r2:.2f}")

plt.figure(figsize=(10, 5))
plt.plot(y_test.values, label='Actual Sales', color='blue')
plt.plot(rf_pred, label='Predicted Sales', color='green', linestyle='--')
plt.title('Actual vs Predicted Sales (Random Forest)')
plt.xlabel('Samples')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.show()

feature_importances = rf_model.feature_importances_

importance_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.title('Feature Importance (Random Forest)')
plt.gca().invert_yaxis()
plt.grid(True)
plt.show()

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("üîç Model Evaluation Report (Random Forest)")
print(f"‚úÖ R¬≤ Score       : {r2:.4f}")
print(f"üìâ RMSE (Error)   : {rmse:.2f}")
print(f"üìâ MAE (Error)    : {mae:.2f}")

xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

mse = mean_squared_error(y_test, y_pred_xgb)
mae = mean_absolute_error(y_test, y_pred_xgb)
r2 = r2_score(y_test, y_pred_xgb)

print(f"üîç XGBoost Model Evaluation:")
print(f"‚úÖ R¬≤ Score       : {r2:.4f}")
print(f"üìâ RMSE (Error)   : {mse**0.5:.2f}")
print(f"üìâ MAE (Error)    : {mae:.2f}")

comparison_data = {
    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest', 'XGBoost'],
    'R2 Score': [0.09, 0.964, 0.0866, 0.9035],
    'RMSE': [21824.98,
             7152.62,
             21824.98,
             7094.16],
    'MAE': [14564.77,
            4954.30,
            14564.77,
            4019.50]
}


model_comparison_df = pd.DataFrame(comparison_data)
model_comparison_df

"""## Final Model Comparison

| Model             | R¬≤ Score | RMSE     | MAE     |
|------------------|----------|----------|---------|
| Linear Regression| 0.0900   | 21824.98 | 14564.77|
| Decision Tree    | 0.9640   | 7152.62  | 4954.30 |
| Random Forest    | 0.0866   | 21824.98 | 14564.77|
| XGBoost ‚úÖ        | 0.9035   | 7094.16  | 4019.50 |

### Best Model: XGBoost  
The XGBoost Regressor gave the best performance with an **R¬≤ Score of 0.90**, making it our final selected model.

# Conclusion

This project demonstrates how machine learning can be used for retail sales prediction.  
By testing multiple models and comparing performance, we found that **XGBoost** offered the best results.



---
"""

# Save cleaned dataset to CSV
merged_df.to_csv('cleaned_retail_data.csv', index=False)

!pip uninstall streamlit -y
!pip install streamlit

import joblib
joblib.dump(xgb_model, 'xgboost_model.pkl')

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import pickle
# 
# # Load model
# with open("xgboost_model.pkl", "rb") as file:
#     model = pickle.load(file)
# 
# # Page config
# st.set_page_config(page_title="Retail Sales Prediction", layout="centered")
# st.title("üõçÔ∏è Retail Sales Predictor")
# st.write("Enter store and date details below to predict weekly sales.")
# 
# # Inputs
# store_id = st.number_input("Store ID", min_value=1, max_value=45, value=1)
# dept = st.number_input("Department", min_value=1, max_value=99, value=1)
# year = st.number_input("Year", min_value=2010, max_value=2025, value=2012)
# month = st.number_input("Month", min_value=1, max_value=12, value=1)
# week = st.number_input("Week", min_value=1, max_value=52, value=1)
# day = st.number_input("Day", min_value=1, max_value=31, value=1)
# day_of_week = st.selectbox("Day of Week", [0, 1, 2, 3, 4, 5, 6])  # 0 = Monday
# temperature = st.number_input("Temperature (¬∞F)", value=70.0)
# fuel_price = st.number_input("Fuel Price (USD)", value=3.0)
# is_promo = st.checkbox("Promotion Active?", value=False)
# size = st.number_input("Store Size (sqft)", value=150000)
# 
# # Store Type one-hot encoding
# store_type = st.selectbox("Store Type", ['A', 'B', 'C'])
# type_a = 1 if store_type == 'A' else 0
# type_b = 1 if store_type == 'B' else 0
# type_c = 1 if store_type == 'C' else 0
# 
# # Convert boolean to int
# is_promo = int(is_promo)
# 
# # Final Input DataFrame
# input_df = pd.DataFrame({
#     "Store_ID": [store_id],
#     "Dept": [dept],
#     "Year": [year],
#     "Month": [month],
#     "Week": [week],
#     "Day": [day],
#     "DayOfWeek": [day_of_week],
#     "Temperature": [temperature],
#     "Fuel_Price": [fuel_price],
#     "IsPromo": [is_promo],
#     "Size": [size],
#     "Type_A": [type_a],
#     "Type_B": [type_b],
#     "Type_C": [type_c]
# })
# 
# # Predict
# if st.button("Predict Weekly Sales"):
#     try:
#         prediction = model.predict(input_df)[0]
#         st.success(f"üìà Predicted Weekly Sales: **${prediction:,.2f}**")
#     except Exception as e:
#         st.error(f"‚ùå Prediction failed: {e}")
#

!npm install -g localtunnel

!streamlit run app.py & npx localtunnel --port 8501

!pip install pyngrok

from pyngrok import ngrok
from google.colab import userdata

NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')
ngrok.set_auth_token(NGROK_AUTH_TOKEN)
!rm -rf ~/.ngrok2

!ngrok config add-authtoken 30S7SiB7GjyYjvVK6sAHyUlIKv0_2Un9FNVrAoKvYnHX9dzof

from pyngrok import ngrok
public_url = ngrok.connect(8501)
print("Your app URL:", public_url)

!streamlit run app.py &